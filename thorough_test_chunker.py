#!/usr/bin/env python3
"""
–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –¢–©–ê–¢–ï–õ–¨–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ Smart Chunker
"""

import json
import re
from pathlib import Path
from collections import Counter

from smart_chunker import SmartDocumentChunker

# –ü—É—Ç–∏
FULLDOCS_DIR = Path(__file__).parent / "fulldocx"
DOCX_FILE = FULLDOCS_DIR / "–ñ–∏–ª–∏—â–Ω—ã–π –∫–æ–¥–µ–∫—Å –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏.docx"
STRUCTURE_FILE = FULLDOCS_DIR / "–ñ–∏–ª–∏—â–Ω—ã–π –∫–æ–¥–µ–∫—Å –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏_structure.txt"

print("=" * 100)
print("–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –¢–©–ê–¢–ï–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê SMART CHUNKER")
print("=" * 100)

chunker = SmartDocumentChunker(DOCX_FILE, STRUCTURE_FILE)
chunks = chunker.extract_text_with_structure()

level_1 = [c for c in chunks if c['level'] == 1]
level_2 = [c for c in chunks if c['level'] == 2]

print(f"\n‚úÖ –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
print(f"   Level 1 (—Å—Ç–∞—Ç—å–∏): {len(level_1)}")
print(f"   Level 2 (–ø—É–Ω–∫—Ç—ã): {len(level_2)}")

# ============================================================================
# –ü–†–û–í–ï–†–ö–ê 1: –°—Ç–∞—Ç—å–∏ –ù–ï —Å–º–µ—à–∏–≤–∞—é—Ç—Å—è
# ============================================================================
print("\n" + "=" * 100)
print("–ü–†–û–í–ï–†–ö–ê 1: –°—Ç–∞—Ç—å–∏ –ù–ï –¥–æ–ª–∂–Ω—ã —Å–º–µ—à–∏–≤–∞—Ç—å—Å—è")
print("=" * 100)

# –î–ª—è –∫–∞–∂–¥–æ–π level 1 —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Å–≤–æ–∏ –ø—É–Ω–∫—Ç—ã
errors_mixing = []

for i, l1_chunk in enumerate(level_1):
    article_title = l1_chunk['metadata']['article']

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ level 2 —á–∞–Ω–∫–∏ —Å —ç—Ç–∏–º –∂–µ –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Å—Ç–∞—Ç—å–∏
    l2_chunks = [c for c in level_2 if c['metadata']['article'] == article_title]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ parent_article —É level 2 —Å–æ–≤–ø–∞–¥–∞–µ—Ç
    for l2 in l2_chunks:
        if l2['parent_article'] != article_title:
            errors_mixing.append({
                'level_1_article': article_title,
                'level_2_parent': l2['parent_article'],
                'level_2_preview': l2['text'][:100]
            })

if errors_mixing:
    print(f"‚ùå –ù–ê–ô–î–ï–ù–û {len(errors_mixing)} –û–®–ò–ë–û–ö —Å–º–µ—à–∏–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–µ–π!")
    for err in errors_mixing[:5]:
        print(f"\n   Level 1: {err['level_1_article']}")
        print(f"   Level 2 parent: {err['level_2_parent']}")
        print(f"   –¢–µ–∫—Å—Ç: {err['level_2_preview']}")
else:
    print("‚úÖ –û—Ç–ª–∏—á–Ω–æ! –°—Ç–∞—Ç—å–∏ –ù–ï —Å–º–µ—à–∏–≤–∞—é—Ç—Å—è")

# ============================================================================
# –ü–†–û–í–ï–†–ö–ê 2: –¢–µ–∫—Å—Ç level 1 —Å–æ–¥–µ—Ä–∂–∏—Ç –í–°–ï –ø—É–Ω–∫—Ç—ã
# ============================================================================
print("\n" + "=" * 100)
print("–ü–†–û–í–ï–†–ö–ê 2: Level 1 (—Å—Ç–∞—Ç—å—è) –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤—Å–µ level 2 (–ø—É–Ω–∫—Ç—ã)")
print("=" * 100)

# –ë–µ—Ä–µ–º 5 —Å–ª—É—á–∞–π–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º
import random
random.seed(42)
test_articles = random.sample(level_1, min(5, len(level_1)))

errors_missing = []

for l1 in test_articles:
    article_title = l1['metadata']['article']
    l1_text = l1['text']

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ level 2 –¥–ª—è —ç—Ç–æ–π —Å—Ç–∞—Ç—å–∏
    l2_chunks = [c for c in level_2 if c['metadata']['article'] == article_title]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–∞–∂–¥—ã–π level 2 —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ level 1
    for l2 in l2_chunks[:10]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 10
        if l2['text'] not in l1_text:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –ø–µ—Ä–≤—ã–º 100 —Å–∏–º–≤–æ–ª–æ–≤ (–º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–ª–∏—á–∏—è)
            if l2['text'][:100] not in l1_text:
                errors_missing.append({
                    'article': article_title,
                    'l2_preview': l2['text'][:100]
                })

if errors_missing:
    print(f"‚ùå –ù–ê–ô–î–ï–ù–û {len(errors_missing)} —Å–ª—É—á–∞–µ–≤ –≥–¥–µ level 2 –ù–ï –≤ level 1!")
    for err in errors_missing[:3]:
        print(f"\n   –°—Ç–∞—Ç—å—è: {err['article']}")
        print(f"   Level 2 —Ç–µ–∫—Å—Ç: {err['l2_preview']}")
else:
    print("‚úÖ –û—Ç–ª–∏—á–Ω–æ! Level 1 —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ Level 2")

# ============================================================================
# –ü–†–û–í–ï–†–ö–ê 3: –ù–µ—Ç –ª–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è —á–∞–Ω–∫–æ–≤
# ============================================================================
print("\n" + "=" * 100)
print("–ü–†–û–í–ï–†–ö–ê 3: –ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —á–∞–Ω–∫–æ–≤")
print("=" * 100)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —Ç–µ–∫—Å—Ç—É
texts = [c['text'] for c in chunks]
duplicates = [item for item, count in Counter(texts).items() if count > 1]

if duplicates:
    print(f"‚ùå –ù–ê–ô–î–ï–ù–û {len(duplicates)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤!")
    for dup in duplicates[:3]:
        print(f"   –¢–µ–∫—Å—Ç: {dup[:100]}...")
else:
    print("‚úÖ –û—Ç–ª–∏—á–Ω–æ! –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ—Ç")

# ============================================================================
# –ü–†–û–í–ï–†–ö–ê 4: –î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
# ============================================================================
print("\n" + "=" * 100)
print("–ü–†–û–í–ï–†–ö–ê 4: –î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π")
print("=" * 100)

test_cases = [
    "–°—Ç–∞—Ç—å—è 1. –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—á–∞–ª–∞ –∂–∏–ª–∏—â–Ω–æ–≥–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞",
    "–°—Ç–∞—Ç—å—è 15. –û–±—ä–µ–∫—Ç—ã –∂–∏–ª–∏—â–Ω—ã—Ö –ø—Ä–∞–≤. –ú–Ω–æ–≥–æ–∫–≤–∞—Ä—Ç–∏—Ä–Ω—ã–π –¥–æ–º",
    "–°—Ç–∞—Ç—å—è 155. –í–Ω–µ—Å–µ–Ω–∏–µ –ø–ª–∞—Ç—ã –∑–∞ –∂–∏–ª–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ –∏ –∫–æ–º–º—É–Ω–∞–ª—å–Ω—ã–µ —É—Å–ª—É–≥–∏",
    "–°—Ç–∞—Ç—å—è 161. –í—ã–±–æ—Ä —Å–ø–æ—Å–æ–±–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–Ω–æ–≥–æ–∫–≤–∞—Ä—Ç–∏—Ä–Ω—ã–º –¥–æ–º–æ–º"
]

for test_article in test_cases:
    l1_chunks = [c for c in level_1 if c['metadata']['article'] == test_article]
    l2_chunks = [c for c in level_2 if c['metadata']['article'] == test_article]

    if not l1_chunks:
        print(f"\n‚ùå {test_article}")
        print(f"   Level 1 –ù–ï –ù–ê–ô–î–ï–ù–ê")
        continue

    l1 = l1_chunks[0]

    print(f"\n‚úÖ {test_article}")
    print(f"   Level 1: {len(l1['text'])} —Å–∏–º–≤–æ–ª–æ–≤, {len(l1['text'].split(chr(10)))} —Å—Ç—Ä–æ–∫")

    # –°—á–∏—Ç–∞–µ–º –ø—É–Ω–∫—Ç—ã –≤ level 1
    l1_lines = l1['text'].split('\n')
    l1_points = [l for l in l1_lines if re.match(r'^\d+\.', l.strip())]
    l1_letters = [l for l in l1_lines if re.match(r'^[–∞-—è–ê-–Ø]\)', l.strip())]

    print(f"   –í Level 1 –Ω–∞–π–¥–µ–Ω–æ: {len(l1_points)} –ø—É–Ω–∫—Ç–æ–≤, {len(l1_letters)} –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤ (–∞, –±, –≤)")
    print(f"   Level 2 —á–∞–Ω–∫–æ–≤: {len(l2_chunks)}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    print(f"   –°—Ç—Ä—É–∫—Ç—É—Ä–∞ Level 2 (–ø–µ—Ä–≤—ã–µ 5):")
    for i, l2 in enumerate(l2_chunks[:5], 1):
        first_line = l2['text'].split('\n')[0]
        print(f"      {i}. {first_line[:80]}")

    if len(l2_chunks) > 5:
        print(f"      ... –∏ –µ—â–µ {len(l2_chunks) - 5} —á–∞–Ω–∫–æ–≤")

# ============================================================================
# –ü–†–û–í–ï–†–ö–ê 5: –ì—Ä–∞–Ω–∏—Ü—ã —Å—Ç–∞—Ç–µ–π - –Ω–µ—Ç –ª–∏ "–ø—Ä—ã–∂–∫–æ–≤"
# ============================================================================
print("\n" + "=" * 100)
print("–ü–†–û–í–ï–†–ö–ê 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–Ω–∏—Ü –º–µ–∂–¥—É —Å—Ç–∞—Ç—å—è–º–∏")
print("=" * 100)

# –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç—å–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É
sorted_articles = sorted(level_1, key=lambda x: x['metadata']['article'])

errors_boundaries = []

# –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å—Ç–∞—Ç—å–∏ –∏–¥—É—Ç –ø–æ–¥—Ä—è–¥ –±–µ–∑ –ø—Ä–æ–ø—É—Å–∫–æ–≤
for i in range(len(sorted_articles) - 1):
    current = sorted_articles[i]
    next_article = sorted_articles[i + 1]

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä–∞ —Å—Ç–∞—Ç–µ–π
    current_num = re.search(r'–°—Ç–∞—Ç—å—è\s+([\d.]+)', current['metadata']['article'])
    next_num = re.search(r'–°—Ç–∞—Ç—å—è\s+([\d.]+)', next_article['metadata']['article'])

    if current_num and next_num:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–µ–∂–¥—É –Ω–∏–º–∏ –Ω–µ—Ç –±–æ–ª—å—à–∏—Ö –ø—Ä–æ–ø—É—Å–∫–æ–≤
        try:
            curr = float(current_num.group(1).replace('.', '.'))
            nxt = float(next_num.group(1).replace('.', '.'))

            # –ï—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –±–æ–ª—å—à–µ 20 - –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ
            if nxt - curr > 20:
                errors_boundaries.append({
                    'current': current['metadata']['article'],
                    'next': next_article['metadata']['article'],
                    'gap': nxt - curr
                })
        except:
            pass

if errors_boundaries:
    print(f"‚ö†Ô∏è  –ù–ê–ô–î–ï–ù–û {len(errors_boundaries)} –±–æ–ª—å—à–∏—Ö –ø—Ä–æ–ø—É—Å–∫–æ–≤ –º–µ–∂–¥—É —Å—Ç–∞—Ç—å—è–º–∏:")
    for err in errors_boundaries[:5]:
        print(f"   {err['current']} ‚Üí {err['next']} (–ø—Ä–æ–ø—É—Å–∫: {err['gap']})")
else:
    print("‚úÖ –û—Ç–ª–∏—á–Ω–æ! –°—Ç–∞—Ç—å–∏ –∏–¥—É—Ç –ø–æ–¥—Ä—è–¥ –±–µ–∑ –±–æ–ª—å—à–∏—Ö –ø—Ä–æ–ø—É—Å–∫–æ–≤")

# ============================================================================
# –ü–†–û–í–ï–†–ö–ê 6: –ü—Ä–æ–≤–µ—Ä–∫–∞ parent-child —Å—Å—ã–ª–æ–∫ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö
# ============================================================================
print("\n" + "=" * 100)
print("–ü–†–û–í–ï–†–ö–ê 6: Parent-child —Å—Å—ã–ª–∫–∏ (–¥–µ—Ç–∞–ª—å–Ω–æ)")
print("=" * 100)

# –ë–µ—Ä–µ–º –°—Ç–∞—Ç—å—é 161 (—Å–∞–º–∞—è –±–æ–ª—å—à–∞—è) –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –µ—ë level 2
test_article = "–°—Ç–∞—Ç—å—è 161. –í—ã–±–æ—Ä —Å–ø–æ—Å–æ–±–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–Ω–æ–≥–æ–∫–≤–∞—Ä—Ç–∏—Ä–Ω—ã–º –¥–æ–º–æ–º. –û–±—â–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é –º–Ω–æ–≥–æ–∫–≤–∞—Ä—Ç–∏—Ä–Ω—ã–º –¥–æ–º–æ–º"
l1_161 = [c for c in level_1 if c['metadata']['article'] == test_article]
l2_161 = [c for c in level_2 if c['metadata']['article'] == test_article]

if l1_161 and l2_161:
    l1 = l1_161[0]
    print(f"\n–°—Ç–∞—Ç—å—è 161 (—Å–∞–º–∞—è –±–æ–ª—å—à–∞—è):")
    print(f"   Level 1 —Ä–∞–∑–º–µ—Ä: {len(l1['text'])} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   Level 2 —á–∞–Ω–∫–æ–≤: {len(l2_161)}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ level 2 —Å—Å—ã–ª–∞—é—Ç—Å—è –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π parent
    wrong_parent = [c for c in l2_161 if c['parent_article'] != test_article]

    if wrong_parent:
        print(f"   ‚ùå {len(wrong_parent)} level 2 —á–∞–Ω–∫–æ–≤ –∏–º–µ—é—Ç –ù–ï–í–ï–†–ù–´–ô parent_article!")
    else:
        print(f"   ‚úÖ –í—Å–µ {len(l2_161)} level 2 —á–∞–Ω–∫–æ–≤ –∏–º–µ—é—Ç –≤–µ—Ä–Ω—ã–π parent_article")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç–µ–∫—Å—Ç level 2 —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ level 1
    not_contained = []
    for l2 in l2_161[:20]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 20
        if l2['text'][:200] not in l1['text']:
            not_contained.append(l2)

    if not_contained:
        print(f"   ‚ùå {len(not_contained)} level 2 —á–∞–Ω–∫–æ–≤ –ù–ï —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –≤ level 1!")
    else:
        print(f"   ‚úÖ –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ level 2 —á–∞–Ω–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –≤ level 1")

# ============================================================================
# –ü–†–û–í–ï–†–ö–ê 7: Metadata –ø–æ–ª–Ω–æ—Ç–∞
# ============================================================================
print("\n" + "=" * 100)
print("–ü–†–û–í–ï–†–ö–ê 7: –ü–æ–ª–Ω–æ—Ç–∞ metadata")
print("=" * 100)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤ –µ—Å—Ç—å –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è
required_fields = ['document', 'type', 'level', 'article']
optional_fields = ['section', 'chapter']

missing_count = 0
incomplete_count = 0

for i, chunk in enumerate(chunks):
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
    for field in required_fields:
        if field not in chunk['metadata']:
            missing_count += 1
            if missing_count <= 3:
                print(f"   –ß–∞–Ω–∫ #{i}: –Ω–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–ª—è '{field}'")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã section –∏–ª–∏ chapter
    if not chunk['metadata'].get('section') and not chunk['metadata'].get('chapter'):
        incomplete_count += 1
        if incomplete_count <= 3:
            print(f"   –ß–∞–Ω–∫ #{i}: –Ω–µ—Ç –Ω–∏ section –Ω–∏ chapter")

if missing_count == 0 and incomplete_count == 0:
    print("‚úÖ –û—Ç–ª–∏—á–Ω–æ! Metadata –ø–æ–ª–Ω–∞—è —É –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤")
else:
    print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {missing_count} missing fields, {incomplete_count} incomplete")

# ============================================================================
# –ò–¢–û–ì–û–í–ê–Ø –û–¶–ï–ù–ö–ê
# ============================================================================
print("\n" + "=" * 100)
print("–ò–¢–û–ì–û–í–ê–Ø –û–¶–ï–ù–ö–ê")
print("=" * 100)

all_errors = len(errors_mixing) + len(errors_missing) + len(duplicates) + len(errors_boundaries) + missing_count + incomplete_count

if all_errors == 0:
    print("‚úÖ‚úÖ‚úÖ –í–°–ï –ü–†–û–í–ï–†–ö–ò –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
    print("‚úÖ –ß–∞–Ω–∫–µ—Ä –†–ê–ë–û–¢–ê–ï–¢ –ò–î–ï–ê–õ–¨–ù–û!")
    print("‚úÖ –ú–û–ñ–ù–û –°–û–ó–î–ê–í–ê–¢–¨ –í–ï–ö–¢–û–†–ù–£–Æ –ë–ê–ó–£!")
else:
    print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {all_errors} –ø—Ä–æ–±–ª–µ–º (—Å–º. –≤—ã—à–µ)")
    print("   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
report = {
    'total_chunks': len(chunks),
    'level_1_count': len(level_1),
    'level_2_count': len(level_2),
    'errors_mixing': len(errors_mixing),
    'errors_missing': len(errors_missing),
    'duplicates': len(duplicates),
    'errors_boundaries': len(errors_boundaries),
    'missing_metadata': missing_count,
    'incomplete_metadata': incomplete_count,
    'total_errors': all_errors,
    'status': 'PASS' if all_errors == 0 else 'FAIL'
}

report_file = Path(__file__).parent / "reports" / "thorough_chunker_test.json"
with open(report_file, 'w', encoding='utf-8') as f:
    json.dump(report, f, ensure_ascii=False, indent=2)

print(f"\nüìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
