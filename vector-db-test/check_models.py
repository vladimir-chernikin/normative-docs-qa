#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–µ–π –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–µ.
–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –≤—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∏—Ö.
–û–Ω –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª–∏ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞, –∞ —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Ö –Ω–∞–ª–∏—á–∏–µ.
"""

import os
import sys
import json
from pathlib import Path

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏
project_root = Path(__file__).parent
config_path = project_root / "config" / "config.json"
models_dir = project_root / "local_models"

# –ú–∞–ø–ø–∏–Ω–≥ –∫–æ—Ä–æ—Ç–∫–∏—Ö –∏–º–µ–Ω –Ω–∞ –ø–æ–ª–Ω—ã–µ –ø—É—Ç–∏ –≤ Hugging Face
MODEL_MAPPING = {
    "rubert-tiny2": "cointegrated/rubert-tiny2",
    "multilingual-e5-small": "intfloat/multilingual-e5-small",
    "paraphrase-multilingual-MiniLM-L12-v2": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    "labse": "sentence-transformers/LaBSE",
    "frida": "ai-forever/FRIDA"
    # "openai-e5-large": "text-embedding-3-large"  # OpenAI –º–æ–¥–µ–ª—å - –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ, —Ç–∞–∫ –∫–∞–∫ —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–µ—à–Ω–∏–π API
}

def load_config():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        return config
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è config.json: {e}")
        return {}

def verify_model_integrity(model_path: Path, model_type: str = "sentence-transformers") -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.
    
    Args:
        model_path: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏
        model_type: –¢–∏–ø –º–æ–¥–µ–ª–∏ (sentence-transformers, transformers, openai)
        
    Returns:
        True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —Ü–µ–ª–æ—Å—Ç–Ω–∞—è, –∏–Ω–∞—á–µ False
    """
    # –î–ª—è OpenAI –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if model_type == "openai":
        # –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ, —Ç–∞–∫ –∫–∞–∫ OpenAI –º–æ–¥–µ–ª–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ
        """
        config_file = model_path / "config.json"
        info_file = model_path / "openai_model_info.txt"
        return config_file.exists() and info_file.exists()
        """
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏
    required_files = ["config.json"]
    model_files = ["model.safetensors", "pytorch_model.bin"]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    for file in required_files:
        if not (model_path / file).exists():
            return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏ (—Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤)
    has_model_file = any((model_path / file).exists() for file in model_files)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏ (–¥–ª—è Frida –∏ –¥—Ä—É–≥–∏—Ö –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π)
    has_sharded_model = any(f.name.startswith("model-") and f.name.endswith(".safetensors") for f in model_path.glob("model-*.safetensors"))
    
    if not (has_model_file or has_sharded_model):
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
    tokenizer_files = ["tokenizer.json", "vocab.txt", "vocab.json"]
    has_tokenizer = any((model_path / file).exists() for file in tokenizer_files)
    if not has_tokenizer:
        return False
        
    return True

def check_models():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–µ–π –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–µ"""
    print("\n" + "="*80)
    print("üîç –ü–†–û–í–ï–†–ö–ê –ù–ê–õ–ò–ß–ò–Ø –ú–û–î–ï–õ–ï–ô")
    print("="*80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = load_config()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –¢–µ–ø–µ—Ä—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    models_config = config.get("models", [])
    
    if not models_config:
        print("‚ùå –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –≤ config.json –ø—É—Å—Ç")
        return False
    
    print(f"üìã –ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {len(models_config)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ local_models
    if not models_dir.exists():
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {models_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        print(f"üí° –°–æ–∑–¥–∞–π—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é —Å–∫—Ä–∏–ø—Ç–∞ download_models.py")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
    all_models_ok = True
    missing_models = []
    
    for model_config in models_config:
        model_name = model_config.get("name")
        model_type = model_config.get("type")
        model_path = models_dir / model_name
        full_model_path = model_config.get("model_path")
        
        print(f"\nüì¶ –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏: {model_name}")
        print(f"  üìÇ –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å: {model_path}")
        print(f"  üåê –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—É—Ç—å: {full_model_path}")
        print(f"  üîß –¢–∏–ø –º–æ–¥–µ–ª–∏: {model_type}")
        
        # –î–ª—è OpenAI –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
        if model_type == "openai":
            # –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ, —Ç–∞–∫ –∫–∞–∫ OpenAI –º–æ–¥–µ–ª–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ
            """
            openai_api_key = os.environ.get("OPENAI_API_KEY")
            if not openai_api_key:
                print(f"  ‚ö†Ô∏è OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
                print(f"  üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ {model_name}")
            else:
                print(f"  ‚úÖ OPENAI_API_KEY –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è OpenAI –º–æ–¥–µ–ª–∏
            if not model_path.exists():
                print(f"  ‚ö†Ô∏è –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –º–æ–¥–µ–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                print(f"  üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç download_models.py –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
                all_models_ok = False
                missing_models.append(model_name)
                continue
            
            if not verify_model_integrity(model_path, model_type):
                print(f"  ‚ö†Ô∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
                print(f"  üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç download_models.py –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
                all_models_ok = False
                missing_models.append(model_name)
                continue
            
            print(f"  ‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞–π–¥–µ–Ω–∞ –∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞")
            """
            print(f"  ‚ö†Ô∏è –ú–æ–¥–µ–ª—å '{model_name}' –∏—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI API –∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ")
            all_models_ok = False
            missing_models.append(model_name)
            continue
        
        # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
        if not model_path.exists():
            print(f"  ‚ùå –ú–æ–¥–µ–ª—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
            all_models_ok = False
            missing_models.append(model_name)
            continue
        
        if not verify_model_integrity(model_path, model_type):
            print(f"  ‚ö†Ô∏è –ú–æ–¥–µ–ª—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω–∞—è")
            all_models_ok = False
            missing_models.append(model_name)
            continue
        
        print(f"  ‚úÖ –ú–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞ –∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞")
    
    print("\n" + "="*80)
    if all_models_ok:
        print("‚úÖ –í–°–ï –ú–û–î–ï–õ–ò –ù–ê–ô–î–ï–ù–´ –ò –ì–û–¢–û–í–´ –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ")
    else:
        print("‚ö†Ô∏è –ù–ï–ö–û–¢–û–†–´–ï –ú–û–î–ï–õ–ò –û–¢–°–£–¢–°–¢–í–£–Æ–¢ –ò–õ–ò –ü–û–í–†–ï–ñ–î–ï–ù–´")
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏: {', '.join(missing_models)}")
        print("\nüí° –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:")
        print("   python download_models.py")
    print("="*80)
    
    return all_models_ok

if __name__ == "__main__":
    success = check_models()
    if not success:
        sys.exit(1) 