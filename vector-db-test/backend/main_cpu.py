#!/usr/bin/env python3
"""
Backend API —Å–µ—Ä–≤–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""

import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import logging
import httpx
import asyncio
from dotenv import load_dotenv

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
from sentence_transformers import SentenceTransformer
from langchain_community.vectorstores import FAISS
from langchain_core.embeddings import Embeddings
from langchain_core.documents import Document

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv(project_root / ".env")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
VECTORDB_DIR = project_root / "vectordb/unified_all_docs_e5"
EMBEDDING_MODEL = "intfloat/multilingual-e5-small"

# YandexGPT –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
YANDEX_API_KEY = os.getenv("YANDEX_API_KEY", "")
YANDEX_FOLDER_ID = os.getenv("YANDEX_FOLDER_ID", "")


async def reformulate_query(original_query: str) -> str:
    """
    –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ç–µ—Ä–º–∏–Ω—ã –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ñ–ö–•
    –∏—Å–ø–æ–ª—å–∑—É—è YandexGPT –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞.
    """
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        # –ï—Å–ª–∏ –Ω–µ—Ç API –∫–ª—é—á–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        logger.info("‚ö†Ô∏è –ù–µ—Ç Yandex API –∫–ª—é—á–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å")
        return original_query

    prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –ñ–ö–• –†–§.
–ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ç–µ—Ä–º–∏–Ω–∞—Ö –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–ü–†–ê–í–ò–õ–ê:
1. –ò—Å–ø–æ–ª—å–∑—É–π –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é –∏–∑ –ñ–ö –†–§, –ü—Ä–∞–≤–∏–ª 354, –ü—Ä–∞–≤–∏–ª 491
2. –ó–∞–º–µ–Ω—è–π —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞ –Ω–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ:
   - "–Ω–∞—á–∏—Å–ª–µ–Ω–∏—è" ‚Üí "—Ä–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ø–ª–∞—Ç—ã"
   - "–ø–ª–∞—Ç–∏—Ç—å –∑–∞ —Å–≤–µ—Ç" ‚Üí "–∫–æ–º–º—É–Ω–∞–ª—å–Ω–∞—è —É—Å–ª—É–≥–∞ –ø–æ —ç–ª–µ–∫—Ç—Ä–æ—Å–Ω–∞–±–∂–µ–Ω–∏—é"
   - "–º–∫–¥" ‚Üí "–º–Ω–æ–≥–æ–∫–≤–∞—Ä—Ç–∏—Ä–Ω—ã–π –¥–æ–º"
   - "–±–∞—Ç–∞—Ä–µ–∏" ‚Üí "–æ—Ç–æ–ø–ª–µ–Ω–∏–µ"
   - "–ø—Ä–æ—Ç–æ–∫–æ–ª —Å–æ–±—Ä–∞–Ω–∏—è" ‚Üí "–ø—Ä–æ—Ç–æ–∫–æ–ª –æ–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤"
   - "–∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è" ‚Üí "–ø–æ—Ä—è–¥–æ–∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è"
3. –°–æ—Ö—Ä–∞–Ω—è–π —Å–º—ã—Å–ª –≤–æ–ø—Ä–æ—Å–∞
4. –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏–∑ —Å—Ç–∞—Ç–µ–π –∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–æ–≤
5. –û—Ç–≤–µ—Ç –¢–û–õ–¨–ö–û –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤–æ–ø—Ä–æ—Å–æ–º, –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π

–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {original_query}

–£–õ–£–ß–®–ï–ù–ù–´–ô –í–û–ü–†–û–°:"""

    url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
    headers = {
        "Authorization": f"Api-Key {YANDEX_API_KEY}",
        "Content-Type": "application/json"
    }

    body = {
        "modelUri": f"gpt://{YANDEX_FOLDER_ID}/yandexgpt-lite",
        "completionOptions": {
            "stream": False,
            "temperature": 0.3,
            "maxTokens": 100
        },
        "messages": [
            {
                "role": "user",
                "text": prompt
            }
        ]
    }

    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.post(url, headers=headers, json=body)
            response.raise_for_status()
            result = response.json()

            # YandexGPT –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç result.alternatives[0].message.text
            reformulated = result["result"]["alternatives"][0]["message"]["text"].strip()

            # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –∏ –ª–∏—à–Ω–µ–µ
            reformulated = reformulated.strip('"').strip("'").strip()

            logger.info(f"üîÑ –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ: '{original_query}' ‚Üí '{reformulated}'")
            return reformulated

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        # –ü—Ä–∏ –æ—à–∏–±–∫–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        return original_query


async def rerank_results_with_llm(query: str, results_with_scores: list) -> list:
    """
    –†–µ—Ä–∞–Ω–∂–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —á–µ—Ä–µ–∑ YandexGPT –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ª—É—á—à–µ–≥–æ –æ—Ç–≤–µ—Ç–∞.

    Args:
        query: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        results_with_scores: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (doc, score)

    Returns:
        –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ (doc, score) –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    """
    if not results_with_scores:
        return results_with_scores

    # –ï—Å–ª–∏ –≤—Å–µ–≥–æ 1 —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –Ω–µ—á–µ–≥–æ —Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞—Ç—å
    if len(results_with_scores) == 1:
        return results_with_scores

    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
    results_text = ""
    for i, (doc, score) in enumerate(results_with_scores, 1):
        similarity = 1 / (1 + score)
        doc_name = doc.metadata.get('document', 'Unknown')
        article = doc.metadata.get('article', '')
        content_preview = doc.page_content[:300].replace('\n', ' ')

        results_text += f"\n{i}. –î–æ–∫—É–º–µ–Ω—Ç: {doc_name}\n"
        results_text += f"   –°—Ç–∞—Ç—å—è: {article}\n"
        results_text += f"   –°—Ö–æ–¥—Å—Ç–≤–æ: {similarity:.2%}\n"
        results_text += f"   –¢–µ–∫—Å—Ç: {content_preview}...\n"

    prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –†–§.
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π, –∫–∞–∫–æ–π –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –õ–£–ß–®–ï –í–°–ï–ì–û –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{query}

–ù–ê–ô–î–ï–ù–ù–´–ï –§–†–ê–ì–ú–ï–ù–¢–´:
{results_text}

–ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò:
1. –ü—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –ø–µ—Ä–µ—á–µ–Ω—å, –ø–æ—Ä—è–¥–æ–∫)
2. –ü–æ–ª–Ω–æ—Ç–∞ –æ—Ç–≤–µ—Ç–∞ (—á–µ–º –ø–æ–ª–Ω–µ–µ, —Ç–µ–º –ª—É—á—à–µ)
3. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (–Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ —Å–æ—Å–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å)
4. –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ (—Å—Ç–∞—Ç—å—è –∑–∞–∫–æ–Ω–∞ –ª—É—á—à–µ —á–µ–º –ø–∏—Å—å–º–æ)

–£–ö–ê–ñ–ò –ù–û–ú–ï–† –õ–£–ß–®–ï–ì–û –§–†–ê–ì–ú–ï–ù–¢–ê (—Ü–∏—Ñ—Ä–æ–π –æ—Ç 1 –¥–æ {len(results_with_scores)}):
"""

    try:
        url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        headers = {
            "Authorization": f"Api-Key {YANDEX_API_KEY}",
            "Content-Type": "application/json"
        }

        body = {
            "modelUri": f"gpt://{YANDEX_FOLDER_ID}/yandexgpt-lite",
            "completionOptions": {
                "stream": False,
                "temperature": 0.3,
                "maxTokens": 50
            },
            "messages": [
                {
                    "role": "user",
                    "text": prompt
                }
            ]
        }

        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.post(url, headers=headers, json=body)
            response.raise_for_status()
            result = response.json()

            llm_answer = result["result"]["alternatives"][0]["message"]["text"].strip()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM
            import re
            match = re.search(r'\b([1-9]|1[0-9])\b', llm_answer)

            if match:
                best_idx = int(match.group(1)) - 1  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ 0-based index
                best_idx = max(0, min(best_idx, len(results_with_scores) - 1))

                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –ø–µ—Ä–≤–æ–µ –º–µ—Å—Ç–æ
                best_result = results_with_scores.pop(best_idx)
                results_with_scores.insert(0, best_result)

                logger.info(f"üéØ LLM —Ä–µ—Ä–∞–Ω–∂–∏–Ω–≥: –≤—ã–±—Ä–∞–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç #{best_idx + 1} –∫–∞–∫ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π")
            else:
                logger.warning(f"‚ö†Ô∏è LLM –Ω–µ –≤–µ—Ä–Ω—É–ª –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä: '{llm_answer}'")

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LLM —Ä–µ—Ä–∞–Ω–∂–∏–Ω–≥–∞: {e}")

    return results_with_scores


class SentenceTransformerEmbeddings(Embeddings):
    def __init__(self, model: SentenceTransformer):
        self.model = model

    def embed_documents(self, texts):
        return self.model.encode(texts, show_progress_bar=False).tolist()

    def embed_query(self, text: str):
        return self.model.encode([text], show_progress_bar=False)[0].tolist()


class QueryRequest(BaseModel):
    query: str
    top_k: Optional[int] = 5


class SearchResult(BaseModel):
    document: str
    article: str
    content: str
    metadata: Dict[str, Any]
    similarity: float  # –î–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–ª–µ —Å—Ö–æ–∂–µ—Å—Ç–∏


# –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ FastAPI
app = FastAPI(
    title="Normative Documents QA API",
    description="API –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –ñ–ö–•",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
vectorstore: Optional[FAISS] = None
model: Optional[SentenceTransformer] = None


@app.on_event("startup")
async def startup_event():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ"""
    global vectorstore, model
    
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ Backend API —Å–µ—Ä–≤–µ—Ä–∞...")
    
    if not VECTORDB_DIR.exists():
        logger.error(f"‚ùå –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {VECTORDB_DIR}")
        raise RuntimeError(f"Vector DB not found: {VECTORDB_DIR}")
    
    try:
        logger.info(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {EMBEDDING_MODEL}")
        model = SentenceTransformer(EMBEDDING_MODEL)
        embeddings = SentenceTransformerEmbeddings(model)
        
        logger.info(f"üíæ –ó–∞–≥—Ä—É–∑–∫–∞ –ë–î –∏–∑ {VECTORDB_DIR}")
        vectorstore = FAISS.load_local(str(VECTORDB_DIR), embeddings, allow_dangerous_deserialization=True)
        
        logger.info("‚úÖ Backend API —Å–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        raise


@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π endpoint"""
    return {
        "service": "Normative Documents QA API",
        "status": "running",
        "version": "1.0.0"
    }


@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è"""
    return {
        "status": "healthy" if vectorstore else "uninitialized",
        "model": EMBEDDING_MODEL,
        "vectordb": str(VECTORDB_DIR)
    }


@app.get("/stats")
async def get_stats():
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î"""
    if not vectorstore:
        raise HTTPException(status_code=503, detail="Vector database not loaded")

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å FAISS
        index = vectorstore.index

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤ = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤
        chunks_count = index.ntotal

        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        # –î–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–ª–∏ —Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ –æ—Ç–¥–µ–ª—å–Ω–æ
        # –ü—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± - –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        documents = set()
        # –ë–µ—Ä–µ–º –ø—Ä–∏–º–µ—Ä –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø)
        # –í —Ä–µ–∞–ª—å–Ω–æ–º —Å–ª—É—á–∞–µ –ª—É—á—à–µ —Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ë–î

        return {
            "documents_count": 18,  # –ò–∑–≤–µ—Å—Ç–Ω–æ –∏–∑ —Å–æ–∑–¥–∞–Ω–∏—è –ë–î
            "chunks_count": chunks_count,
            "model": EMBEDDING_MODEL
        }
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        raise HTTPException(status_code=500, detail=f"Stats error: {str(e)}")


@app.get("/documents")
async def get_documents():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –ë–î"""
    if not vectorstore:
        raise HTTPException(status_code=503, detail="Vector database not loaded")

    try:
        # –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–∑–¥–∞–Ω–∏—è –ë–î
        documents = [
            "–ñ–∏–ª–∏—â–Ω—ã–π –∫–æ–¥–µ–∫—Å –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏",
            "–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –∫–æ–¥–µ–∫—Å –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏ (—á–∞—Å—Ç—å –ø–µ—Ä–≤–∞—è)",
            "–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –∫–æ–¥–µ–∫—Å –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏ (—á–∞—Å—Ç—å –≤—Ç–æ—Ä–∞—è)",
            "–ü–ü –†–§ –æ—Ç 06.05.2011 ‚Ññ 354",
            "–ü–ü –†–§ –æ—Ç 13.08.2006 ‚Ññ 491",
            "–ü–ü –†–§ –æ—Ç 23.09.2010 ‚Ññ 731",
            "–ü–ü –†–§ –æ—Ç 16.04.2013 ‚Ññ 344",
            "–ü–ü –†–§ –æ—Ç 05.05.2011 ‚Ññ 355",
            "–ü–ü –†–§ –æ—Ç 14.02.2012 ‚Ññ 128",
            "–ü–ü –†–§ –æ—Ç 15.05.2013 ‚Ññ 416",
            "–ü–ü –†–§ –æ—Ç 06.02.2011 ‚Ññ 56",
            "–ü–ü –†–§ –æ—Ç 04.05.2012 ‚Ññ 439",
            "–ü–ü –†–§ –æ—Ç 13.08.2006 ‚Ññ 491",
            "–ü–ü –†–§ –æ—Ç 27.08.2016 ‚Ññ 857",
            "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–§ –æ—Ç 26.09.2014 ‚Ññ 976",
            "–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –∑–∞–∫–æ–Ω –æ—Ç 27.07.2010 ‚Ññ 190-–§–ó",
            "–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –∑–∞–∫–æ–Ω –æ—Ç 21.12.2013 ‚Ññ 361-–§–ó",
            "–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –∑–∞–∫–æ–Ω –æ—Ç 31.12.2017 ‚Ññ 506-–§–ó"
        ]

        return {"documents": documents}
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=f"Documents error: {str(e)}")


@app.post("/search", response_model=List[SearchResult])
async def search_documents(request: QueryRequest):
    """
    –ü–æ–∏—Å–∫ –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º

    Args:
        request: –ó–∞–ø—Ä–æ—Å —Å —Ç–µ–∫—Å—Ç–æ–º –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    """
    if not vectorstore:
        raise HTTPException(status_code=503, detail="Vector database not loaded")

    try:
        # –®–∞–≥ 1: –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ YandexGPT –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏
        reformulated_query = await reformulate_query(request.query)

        # –®–∞–≥ 2: –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Å—Ä–µ–¥–∏ –±–æ–ª—å—à–µ–≥–æ —á–∏—Å–ª–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (—É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π k)
        # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞–π—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω –Ω–∞ 2-3 –º–µ—Å—Ç–µ
        search_k = max(request.top_k * 2, 10)  # –ú–∏–Ω–∏–º—É–º 10 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        results_with_scores = vectorstore.similarity_search_with_score(reformulated_query, k=search_k)

        # –®–∞–≥ 3: –†–µ—Ä–∞–Ω–∂–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ YandexGPT –¥–ª—è –ª—É—á—à–µ–≥–æ –æ—Ç–≤–µ—Ç–∞
        # –≠—Ç–æ –ü–ï–†–í–ò–ß–ù–´–ô —Ä–µ—Ä–∞–Ω–∂–∏–Ω–≥ - –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π –æ—Ç–≤–µ—Ç —Å—Ä–µ–¥–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        results_with_scores = await rerank_results_with_llm(request.query, results_with_scores)

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        formatted_results = []
        for doc, score in results_with_scores[:request.top_k]:  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            metadata = doc.metadata
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º score –≤ similarity (0-1, –≥–¥–µ 1 = –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ—Ö–æ–∂–∏–π)
            similarity = 1 / (1 + score)
            formatted_results.append(SearchResult(
                document=metadata.get('document', 'Unknown'),
                article=metadata.get('article', ''),
                content=doc.page_content,  # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –æ–±—Ä–µ–∑–∞–Ω–∏—è
                metadata=metadata,
                similarity=round(similarity, 4)  # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ 4 –∑–Ω–∞–∫–æ–≤
            ))

        logger.info(f"üîç –ü–æ–∏—Å–∫: '{request.query[:50]}...' -> –Ω–∞–π–¥–µ–Ω–æ: {len(formatted_results)} (–ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(results_with_scores)})")

        return formatted_results

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
        raise HTTPException(status_code=500, detail=f"Search error: {str(e)}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"""
    import uvicorn
    
    logger.info("=" * 80)
    logger.info("–ó–ê–ü–£–°–ö BACKEND API –°–ï–†–í–ï–†–ê")
    logger.info("=" * 80)
    logger.info(f"üìç API endpoint: http://0.0.0.0:8001")
    logger.info(f"üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://0.0.0.0:8001/docs")
    logger.info("=" * 80)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8001,
        log_level="info"
    )


if __name__ == "__main__":
    main()
