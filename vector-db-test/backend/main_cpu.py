#!/usr/bin/env python3
"""
Backend API —Å–µ—Ä–≤–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""

import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import logging
import httpx
import asyncio
import json
from dotenv import load_dotenv

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
from sentence_transformers import SentenceTransformer
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
# –î–æ–±–∞–≤–ª—è–µ–º parent –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ utils
sys.path.insert(0, str(project_root.parent))
from utils.embeddings import SentenceTransformerEmbeddings

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
load_dotenv(project_root.parent / ".env")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
VECTORDB_DIR = project_root / "vectordb"
EMBEDDING_MODEL = "intfloat/multilingual-e5-base"

# YandexGPT –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
YANDEX_API_KEY = os.getenv("YANDEX_API_KEY", "")
YANDEX_FOLDER_ID = os.getenv("YANDEX_FOLDER_ID", "")


async def reformulate_query(original_query: str) -> tuple[str, int]:
    """
    –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ç–µ—Ä–º–∏–Ω—ã –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ñ–ö–•
    –∏—Å–ø–æ–ª—å–∑—É—è YandexGPT –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞.

    Returns:
        (–ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π_–∑–∞–ø—Ä–æ—Å, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–∫–µ–Ω–æ–≤)
    """
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        # –ï—Å–ª–∏ –Ω–µ—Ç API –∫–ª—é—á–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        logger.info("‚ö†Ô∏è –ù–µ—Ç Yandex API –∫–ª—é—á–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å")
        return original_query, 0

    prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –ñ–ö–• –†–§.
–ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ç–µ—Ä–º–∏–Ω–∞—Ö –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–ü–†–ê–í–ò–õ–ê:
1. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é –∏–∑ –ñ–ö –†–§, –ü—Ä–∞–≤–∏–ª 354, –ü—Ä–∞–≤–∏–ª 491
2. –í–°–ï–ì–î–ê –ø—Ä–∏–≤–æ–¥–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–µ —Ñ—Ä–∞–∑—ã –∫ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º —Ç–µ—Ä–º–∏–Ω–∞–º:
   - "—Å–º–µ–Ω–∏—Ç—å –£–ö" ‚Üí "—Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ –¥–æ–≥–æ–≤–æ—Ä–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–Ω–æ–≥–æ–∫–≤–∞—Ä—Ç–∏—Ä–Ω—ã–º –¥–æ–º–æ–º"
   - "–∫–∞–∫ —Å–º–µ–Ω–∏—Ç—å —É–ø—Ä–∞–≤–ª—è—é—â—É—é –∫–æ–º–ø–∞–Ω–∏—é" ‚Üí "—Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ –∏–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–æ–≥–æ–≤–æ—Ä–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è"
   - "–∫—Ç–æ –ø–ª–∞—Ç–∏—Ç" ‚Üí "–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç—å –ø–æ –≤–Ω–µ—Å–µ–Ω–∏—é –ø–ª–∞—Ç—ã, —Ä–∞–∑–º–µ—Ä –ø–ª–∞—Ç—ã"
   - "–Ω–∞—á–∏—Å–ª–µ–Ω–∏—è" ‚Üí "—Ä–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ø–ª–∞—Ç—ã"
   - "–ø–ª–∞—Ç–∏—Ç—å –∑–∞ —Å–≤–µ—Ç" ‚Üí "–∫–æ–º–º—É–Ω–∞–ª—å–Ω–∞—è —É—Å–ª—É–≥–∞ –ø–æ —ç–ª–µ–∫—Ç—Ä–æ—Å–Ω–∞–±–∂–µ–Ω–∏—é"
   - "–º–∫–¥" ‚Üí "–º–Ω–æ–≥–æ–∫–≤–∞—Ä—Ç–∏—Ä–Ω—ã–π –¥–æ–º"
   - "–±–∞—Ç–∞—Ä–µ–∏" ‚Üí "–æ—Ç–æ–ø–ª–µ–Ω–∏–µ"
   - "–ø—Ä–æ—Ç–æ–∫–æ–ª —Å–æ–±—Ä–∞–Ω–∏—è" ‚Üí "–ø—Ä–æ—Ç–æ–∫–æ–ª –æ–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤"
   - "–∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è" ‚Üí "–ø–æ—Ä—è–¥–æ–∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è"
   - "—á—Ç–æ —Ç–∞–∫–æ–µ" ‚Üí "–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –ø–æ–Ω—è—Ç–∏–µ"
   - "—á—Ç–æ –≤—Ö–æ–¥–∏—Ç" ‚Üí "—Å–æ—Å—Ç–∞–≤, –ø–µ—Ä–µ—á–µ–Ω—å, –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è"
3. –°–æ—Ö—Ä–∞–Ω—è–π —Å–º—ã—Å–ª –≤–æ–ø—Ä–æ—Å–∞
4. –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏–∑ —Å—Ç–∞—Ç–µ–π –∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–æ–≤
5. –î–æ–±–∞–≤–ª—è–π —Å–∏–Ω–æ–Ω–∏–º—ã –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞:
   - "–æ–±—â–µ–µ –∏–º—É—â–µ—Å—Ç–≤–æ" ‚Üí –¥–æ–±–∞–≤–ª—è–π "–ø–æ–º–µ—â–µ–Ω–∏—è –æ–±—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è, –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã, –Ω–µ—Å—É—â–∏–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"
   - "–ø—Ä–∞–≤–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞" ‚Üí –¥–æ–±–∞–≤–ª—è–π "–ø—Ä–∞–≤–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏, –≤–ª–∞–¥–µ–Ω–∏–µ, –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ, —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–µ"
   - "–∫–æ–º–º—É–Ω–∞–ª—å–Ω—ã–µ –ø–ª–∞—Ç–µ–∂–∏" ‚Üí –¥–æ–±–∞–≤–ª—è–π "—Ä–∞–∑–º–µ—Ä –ø–ª–∞—Ç—ã, —Ç–∞—Ä–∏—Ñ—ã, –Ω–æ—Ä–º–∞—Ç–∏–≤—ã, —Ä–∞—Å—á–µ—Ç"
   - "–≤—Ö–æ–¥–∏—Ç –≤ —Å–æ—Å—Ç–∞–≤" ‚Üí –¥–æ–±–∞–≤–ª—è–π "—Å–æ—Å—Ç–∞–≤, –ø–µ—Ä–µ—á–µ–Ω—å, –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è"
6. –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —É–ø–æ–º—è–Ω—É—Ç—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
   –ï–°–õ–ò –≤ –∑–∞–ø—Ä–æ—Å–µ –£–ü–û–ú–ò–ù–ê–ï–¢–°–Ø –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç (–ü—Ä–∞–≤–∏–ª–∞ 354, –ñ–ö –†–§, –ü–ü 491, –ü—Ä–∞–≤–∏–ª–∞ 306, –ì–ö –†–§ –∏ —Ç.–¥.):
   - –î–û–ë–ê–í–¨ –≤ –Ω–∞—á–∞–ª–æ –∑–∞–ø—Ä–æ—Å–∞: "–Ω–∞–π–¥–∏ –≤ [–ø–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞]"
   - –ò—Å–ø–æ–ª—å–∑—É–π –ü–û–õ–ù–û–ï –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ —ç—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞:
     * "–ü—Ä–∞–≤–∏–ª–∞ 354" ‚Üí "–Ω–∞–π–¥–∏ –≤ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–§ –æ—Ç 06.05.2011 ‚Ññ 354 –ü—Ä–∞–≤–∏–ª–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–æ–º–º—É–Ω–∞–ª—å–Ω—ã—Ö —É—Å–ª—É–≥"
     * "–ü—Ä–∞–≤–∏–ª–∞ 306" ‚Üí "–Ω–∞–π–¥–∏ –≤ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–§ –æ—Ç 23.05.2006 ‚Ññ 306 –ü—Ä–∞–≤–∏–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–æ—Ä–º–∞—Ç–∏–≤–æ–≤ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è"
     * "–ü—Ä–∞–≤–∏–ª–∞ 491" ‚Üí "–Ω–∞–π–¥–∏ –≤ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–§ –æ—Ç 13.08.2006 ‚Ññ 491 –û–± —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–∏ –ü—Ä–∞–≤–∏–ª —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –æ–±—â–µ–≥–æ –∏–º—É—â–µ—Å—Ç–≤–∞ –≤ –ú–ö–î"
     * "–ü–ü 290" ‚Üí "–Ω–∞–π–¥–∏ –≤ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–§ –æ—Ç 03.04.2013 ‚Ññ 290 –û –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º –ø–µ—Ä–µ—á–Ω–µ —É—Å–ª—É–≥"
     * "–ü–ü 75" ‚Üí "–Ω–∞–π–¥–∏ –≤ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–§ –æ—Ç 06.02.2006 ‚Ññ 75 –û–± –æ—Ç–∫—Ä—ã—Ç–æ–º –∫–æ–Ω–∫—É—Ä—Å–µ"
     * "–ü–ü 124" ‚Üí "–Ω–∞–π–¥–∏ –≤ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–§ –æ—Ç 14.02.2012 ‚Ññ 124 –û –ø—Ä–∞–≤–∏–ª–∞—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö"
     * "–ü–ü 416" ‚Üí "–Ω–∞–π–¥–∏ –≤ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–§ –æ—Ç 15.05.2013 ‚Ññ 416 –û –ø–æ—Ä—è–¥–∫–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ú–ö–î"
     * "–ü–ü 1110" ‚Üí "–Ω–∞–π–¥–∏ –≤ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–§ –æ—Ç 28.10.2014 ‚Ññ 1110 –û –ª–∏—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–∏–∏"
     * "–ñ–ö –†–§" ‚Üí "–Ω–∞–π–¥–∏ –≤ –ñ–∏–ª–∏—â–Ω–æ–º –∫–æ–¥–µ–∫—Å–µ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏"
     * "–ì–ö –†–§" –∏–ª–∏ "–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –∫–æ–¥–µ–∫—Å" ‚Üí "–Ω–∞–π–¥–∏ –≤ –ì—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–º –∫–æ–¥–µ–∫—Å–µ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏"
     * "–§–ó 261" ‚Üí "–Ω–∞–π–¥–∏ –≤ –§–µ–¥–µ—Ä–∞–ª—å–Ω–æ–º –∑–∞–∫–æ–Ω–µ –æ—Ç 23.11.2009 ‚Ññ 261-–§–ó –û–± —ç–Ω–µ—Ä–≥–æ—Å–±–µ—Ä–µ–∂–µ–Ω–∏–∏"
     * "–§–ó 152" ‚Üí "–Ω–∞–π–¥–∏ –≤ –§–µ–¥–µ—Ä–∞–ª—å–Ω–æ–º –∑–∞–∫–æ–Ω–µ –æ—Ç 27.07.2006 ‚Ññ 152-–§–ó –û –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
     * "–§–ó 190" ‚Üí "–Ω–∞–π–¥–∏ –≤ –§–µ–¥–µ—Ä–∞–ª—å–Ω–æ–º –∑–∞–∫–æ–Ω–µ –æ—Ç 27.07.2010 ‚Ññ 190-–§–ó –û —Ç–µ–ø–ª–æ—Å–Ω–∞–±–∂–µ–Ω–∏–∏"
     * "–ü—Ä–∏–∫–∞–∑ 938" ‚Üí "–Ω–∞–π–¥–∏ –≤ –ü—Ä–∏–∫–∞–∑–µ –ú–∏–Ω—Å—Ç—Ä–æ—è –†–§ –æ—Ç 25.12.2015 ‚Ññ 938 –ø—Ä –û–± —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–∏ –ü–æ—Ä—è–¥–∫–∞"
     * "–ü—Ä–∏–∫–∞–∑ 44" ‚Üí "–Ω–∞–π–¥–∏ –≤ –ü—Ä–∏–∫–∞–∑–µ –ú–∏–Ω—Å—Ç—Ä–æ—è –†–§ –æ—Ç 28.01.2019 ‚Ññ 44 –ø—Ä –û–± —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–∏ –¢—Ä–µ–±–æ–≤–∞–Ω–∏–π"
   - –ï–°–õ–ò —É–ø–æ–º—è–Ω—É—Ço –ù–ï–°–ö–û–õ–¨–ö–û –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: –ø–µ—Ä–µ—á–∏—Å–ª–∏ –í–°–ï —á–µ—Ä–µ–∑ "–∏–ª–∏"

7. –ò–°–ö–õ–Æ–ß–ê–ô —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏—è –∏ –ø–∏—Å—å–º–∞: –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç "–∫–∞–∫ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –ø–æ –ü—Ä–∞–≤–∏–ª–∞–º 354",
   –ù–ï –¥–æ–±–∞–≤–ª—è–π –≤ –æ—Ç–≤–µ—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ –ü–∏—Å—å–º–∞ –ú–∏–Ω—Å—Ç—Ä–æ—è –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Ä–∞–∑—ä—è—Å–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.
   –ò–©–ò –¢–û–õ–¨–ö–û –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ, –∫–æ—Ç–æ—Ä—ã–π —É–∫–∞–∑–∞–Ω –≤ –∑–∞–ø—Ä–æ—Å–µ.

8. –û—Ç–≤–µ—Ç –¢–û–õ–¨–ö–û –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤–æ–ø—Ä–æ—Å–æ–º, –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π

–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {original_query}

–£–õ–£–ß–®–ï–ù–ù–´–ô –í–û–ü–†–û–°:"""

    url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
    headers = {
        "Authorization": f"Api-Key {YANDEX_API_KEY}",
        "Content-Type": "application/json"
    }

    body = {
        "modelUri": f"gpt://{YANDEX_FOLDER_ID}/yandexgpt-lite",
        "completionOptions": {
            "stream": False,
            "temperature": 0.3,
            "maxTokens": 100
        },
        "messages": [
            {
                "role": "user",
                "text": prompt
            }
        ]
    }

    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.post(url, headers=headers, json=body)
            response.raise_for_status()
            result = response.json()

            # YandexGPT –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç result.alternatives[0].message.text
            reformulated = result["result"]["alternatives"][0]["message"]["text"].strip()

            # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –∏ –ª–∏—à–Ω–µ–µ
            reformulated = reformulated.strip('"').strip("'").strip()

            # –ò–°–ü–†–ê–í–õ–ï–ù–û (2026-01-07): –î–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤
            tokens_used = int(result["result"]["usage"]["totalTokens"])

            logger.info(f"üîÑ –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ: '{original_query}' ‚Üí '{reformulated}' ({tokens_used} —Ç–æ–∫–µ–Ω–æ–≤)")
            return reformulated, tokens_used

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        # –ü—Ä–∏ –æ—à–∏–±–∫–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∏ 0 —Ç–æ–∫–µ–Ω–æ–≤
        return original_query, 0


async def validate_results_with_llm(query: str, results_with_scores: list, top_k: int = 3) -> tuple[bool, str]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç –ª–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ö–û–ù–ö–†–ï–¢–ù–´–ô –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å.

    Args:
        query: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        results_with_scores: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (doc, score)
        top_k: –°–∫–æ–ª—å–∫–æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å

    Returns:
        (is_valid, reason) - –≥–¥–µ is_valid=True –µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç
    """
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        # –ï—Å–ª–∏ –Ω–µ—Ç API –∫–ª—é—á–∞, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞
        return True, "–ù–µ—Ç API –∫–ª—é—á–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏"

    # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–∞–ª–æ - –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ
    results_to_check = results_with_scores[:min(len(results_with_scores), top_k)]

    if len(results_to_check) == 0:
        return False, "–ü–æ–∏—Å–∫ –Ω–µ –Ω–∞—à–µ–ª –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    fragments_text = ""
    for i, (doc, score) in enumerate(results_to_check, 1):
        similarity = 1.0 / (1.0 + score)
        content_preview = doc.page_content[:800].replace('\n', ' ')
        metadata = doc.metadata
        doc_name = metadata.get('document', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        article = metadata.get('article', '')

        fragments_text += f"\n–§—Ä–∞–≥–º–µ–Ω—Ç {i} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {similarity:.1%}):\n"
        fragments_text += f"–î–æ–∫—É–º–µ–Ω—Ç: {doc_name}\n"
        if article:
            fragments_text += f"–°—Ç–∞—Ç—å—è: {article}\n"
        fragments_text += f"–¢–µ–∫—Å—Ç: {content_preview}...\n"

    prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –ñ–ö–• –†–§.
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {query}

–ù–ê–ô–î–ï–ù–ù–´–ï –§–†–ê–ì–ú–ï–ù–¢–´ –ù–û–†–ú–ê–¢–ò–í–ù–´–• –î–û–ö–£–ú–ï–ù–¢–û–í:{fragments_text}

–ó–ê–î–ê–ß–ê:
–û–ø—Ä–µ–¥–µ–ª–∏, —Å–æ–¥–µ—Ä–∂–∞—Ç –ª–∏ —ç—Ç–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –ö–û–ù–ö–†–ï–¢–ù–´–ô –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–ö–†–ò–¢–ï–†–ò–ò:
1. ‚úÖ –ö–û–ù–ö–†–ï–¢–ù–´–ô –û–¢–í–ï–¢ –ï–°–¢–¨, –µ—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç:
   - –ß–µ—Ç–∫–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ/–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç—å/–ø—Ä–∞–≤–∏–ª–æ
   - –ü–æ—Ä—è–¥–æ–∫ –¥–µ–π—Å—Ç–≤–∏–π/–∞–ª–≥–æ—Ä–∏—Ç–º
   - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—Ä–æ–∫–∏
   - –ü–µ—Ä–µ—á–µ–Ω—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤/—É—Å–ª—É–≥
   - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–Ω—è—Ç–∏—è
   - –ê–¥—Ä–µ—Å–∞—Ç –¥–µ–π—Å—Ç–≤–∏—è (–∫—Ç–æ –¥–æ–ª–∂–µ–Ω —á—Ç–æ —Å–¥–µ–ª–∞—Ç—å)

2. ‚ùå –ö–û–ù–ö–†–ï–¢–ù–û–ì–û –û–¢–í–ï–¢–ê –ù–ï–¢, –µ—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç:
   - –¢–æ–ª—å–∫–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
   - –ö–æ—Å–≤–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏
   - –î—Ä—É–≥—É—é —Ç–µ–º—É (—Ö–æ—Ç—è –±—ã –ø–æ—Ö–æ–∂–∏–µ —Å–ª–æ–≤–∞)
   - –û–±—â–∏–µ —Ñ—Ä–∞–∑—ã –±–µ–∑ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –ø–æ–ª—å–∑—ã

–û–¢–í–ï–¢:
–ï—Å–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –ï–°–¢–¨ - –Ω–∞–ø–∏—à–∏: "–î–ê: [–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ]"
–ï—Å–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –ù–ï–¢ - –Ω–∞–ø–∏—à–∏: "–ù–ï–¢: [–ø—Ä–∏—á–∏–Ω–∞ –ø–æ—á–µ–º—É –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ –≤ 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏]"

–ü—Ä–∏–º–µ—Ä—ã:
- –í–æ–ø—Ä–æ—Å: "–ì–¥–µ –≤–∑—è—Ç—å —Å–ø—Ä–∞–≤–∫—É –æ —Å–µ–º—å–µ?"
  –§—Ä–∞–≥–º–µ–Ω—Ç: "–ì—Ä–∞–∂–¥–∞–Ω–µ —Å–Ω–∏–º–∞—é—Ç—Å—è —Å —É—á–µ—Ç–∞ –≤ —Å–ª—É—á–∞–µ –ø–æ–¥–∞—á–∏ –∑–∞—è–≤–ª–µ–Ω–∏—è..."
  –û—Ç–≤–µ—Ç: –ù–ï–¢: —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–æ—Ü–µ–¥—É—Ä—É —Å–Ω—è—Ç–∏—è —Å —É—á–µ—Ç–∞, –∞ –Ω–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—ã–¥–∞—á–µ —Å–ø—Ä–∞–≤–æ–∫

- –í–æ–ø—Ä–æ—Å: "–ö–∞–∫ —á–∞—Å—Ç–æ –ø—Ä–æ–≤–æ–¥–∏—Ç—å —Å–æ–±—Ä–∞–Ω–∏—è?"
  –§—Ä–∞–≥–º–µ–Ω—Ç: "–û–±—â–∏–µ —Å–æ–±—Ä–∞–Ω–∏—è –ø—Ä–æ–≤–æ–¥—è—Ç—Å—è –Ω–µ —Ä–µ–∂–µ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–∞ –≤ –≥–æ–¥..."
  –û—Ç–≤–µ—Ç: –î–ê: —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–µ—Ä–∏–æ–¥–∏—á–Ω–æ—Å—Ç—å –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –æ–±—â–∏—Ö —Å–æ–±—Ä–∞–Ω–∏–π

–¢–≤–æ–π –æ—Ç–≤–µ—Ç:"""

    try:
        url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        headers = {
            "Authorization": f"Api-Key {YANDEX_API_KEY}",
            "Content-Type": "application/json"
        }

        body = {
            "modelUri": f"gpt://{YANDEX_FOLDER_ID}/yandexgpt-lite",
            "completionOptions": {
                "stream": False,
                "temperature": 0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
                "maxTokens": 50
            },
            "messages": [
                {
                    "role": "user",
                    "text": prompt
                }
            ]
        }

        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(url, headers=headers, json=body)
            response.raise_for_status()
            result = response.json()

        llm_answer = result["result"]["alternatives"][0]["message"]["text"].strip()
        logger.info(f"ü§ñ –í–∞–ª–∏–¥–∞—Ü–∏—è LLM: {llm_answer}")

        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
        if llm_answer.startswith("–î–ê:"):
            return True, llm_answer[4:].strip()
        elif llm_answer.startswith("–ù–ï–¢:"):
            return False, llm_answer[5:].strip()
        else:
            # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –æ—Ç–≤–µ—Ç –µ—Å—Ç—å
            logger.warning(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ LLM: {llm_answer}")
            return True, "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å"

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        # –ü—Ä–∏ –æ—à–∏–±–∫–µ —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞
        return True, f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}"


async def rerank_results_with_llm(query: str, results_with_scores: list) -> list:
    """
    –†–µ—Ä–∞–Ω–∂–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —á–µ—Ä–µ–∑ YandexGPT –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ª—É—á—à–µ–≥–æ –æ—Ç–≤–µ—Ç–∞.

    Args:
        query: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        results_with_scores: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (doc, score)

    Returns:
        –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ (doc, score) –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    """
    if not results_with_scores:
        return results_with_scores

    # –ï—Å–ª–∏ –≤—Å–µ–≥–æ 1 —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –Ω–µ—á–µ–≥–æ —Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞—Ç—å
    if len(results_with_scores) == 1:
        return results_with_scores

    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
    results_text = ""
    for i, (doc, score) in enumerate(results_with_scores, 1):
        similarity = 1 / (1 + score)
        doc_name = doc.metadata.get('document', 'Unknown')
        article = doc.metadata.get('article', '')
        content_preview = doc.page_content[:300].replace('\n', ' ')

        results_text += f"\n{i}. –î–æ–∫—É–º–µ–Ω—Ç: {doc_name}\n"
        results_text += f"   –°—Ç–∞—Ç—å—è: {article}\n"
        results_text += f"   –°—Ö–æ–¥—Å—Ç–≤–æ: {similarity:.2%}\n"
        results_text += f"   –¢–µ–∫—Å—Ç: {content_preview}...\n"

    prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –†–§.
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π, –∫–∞–∫–æ–π –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –õ–£–ß–®–ï –í–°–ï–ì–û –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{query}

–ù–ê–ô–î–ï–ù–ù–´–ï –§–†–ê–ì–ú–ï–ù–¢–´:
{results_text}

–ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò:
1. –ü—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –ø–µ—Ä–µ—á–µ–Ω—å, –ø–æ—Ä—è–¥–æ–∫)
2. –ü–æ–ª–Ω–æ—Ç–∞ –æ—Ç–≤–µ—Ç–∞ (—á–µ–º –ø–æ–ª–Ω–µ–µ, —Ç–µ–º –ª—É—á—à–µ)
3. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (–Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ —Å–æ—Å–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å)
4. –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ (—Å—Ç–∞—Ç—å—è –∑–∞–∫–æ–Ω–∞ –ª—É—á—à–µ —á–µ–º –ø–∏—Å—å–º–æ)

–£–ö–ê–ñ–ò –ù–û–ú–ï–† –õ–£–ß–®–ï–ì–û –§–†–ê–ì–ú–ï–ù–¢–ê (—Ü–∏—Ñ—Ä–æ–π –æ—Ç 1 –¥–æ {len(results_with_scores)}):
"""

    try:
        url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        headers = {
            "Authorization": f"Api-Key {YANDEX_API_KEY}",
            "Content-Type": "application/json"
        }

        body = {
            "modelUri": f"gpt://{YANDEX_FOLDER_ID}/yandexgpt-lite",
            "completionOptions": {
                "stream": False,
                "temperature": 0.3,
                "maxTokens": 50
            },
            "messages": [
                {
                    "role": "user",
                    "text": prompt
                }
            ]
        }

        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.post(url, headers=headers, json=body)
            response.raise_for_status()
            result = response.json()

            llm_answer = result["result"]["alternatives"][0]["message"]["text"].strip()

            logger.info(f"üìù –û—Ç–≤–µ—Ç YandexGPT: {llm_answer}")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM
            import re
            match = re.search(r'\b([1-9]|1[0-9]|20)\b', llm_answer)

            if match:
                best_idx = int(match.group(1)) - 1  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ 0-based index
                best_idx = max(0, min(best_idx, len(results_with_scores) - 1))

                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –ø–µ—Ä–≤–æ–µ –º–µ—Å—Ç–æ —Å –≤—ã—Å–æ–∫–æ–π –æ—Ü–µ–Ω–∫–æ–π
                best_doc, best_score = results_with_scores.pop(best_idx)
                # –î–∞–µ–º –≤—ã—Å–æ–∫—É—é –æ—Ü–µ–Ω–∫—É 0.99 —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É LLM
                results_with_scores.insert(0, (best_doc, 0.99))

                logger.info(f"üéØ LLM —Ä–µ—Ä–∞–Ω–∂–∏–Ω–≥: –≤—ã–±—Ä–∞–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç #{best_idx + 1} –∫–∞–∫ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π (–æ—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞: {best_score:.3f} -> 0.99)")
            else:
                logger.warning(f"‚ö†Ô∏è LLM –Ω–µ –≤–µ—Ä–Ω—É–ª –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä: '{llm_answer}'")

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LLM —Ä–µ—Ä–∞–Ω–∂–∏–Ω–≥–∞: {e}")

    return results_with_scores


class QueryRequest(BaseModel):
    query: str
    top_k: Optional[int] = 5


class SearchResult(BaseModel):
    document: str
    article: str
    content: str
    metadata: Dict[str, Any]
    similarity: float  # –î–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–ª–µ —Å—Ö–æ–∂–µ—Å—Ç–∏


class SearchResponse(BaseModel):
    results: List[SearchResult]
    reformulated_query: str  # –£—Ç–æ—á–Ω–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –æ—Ç YandexGPT
    original_query: str  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    tokens_used: int = 0  # –ò–°–ü–†–ê–í–õ–ï–ù–û (2026-01-07): –î–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–ª–µ —Ç–æ–∫–µ–Ω–æ–≤


class SimplifyRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ —É–ø—Ä–æ—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞"""
    text: str
    max_length: Optional[int] = 300


class SimplifyResult(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —É–ø—Ä–æ—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞"""
    original_text: str
    simplified_text: str
    tokens_used: int


# –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ FastAPI
app = FastAPI(
    title="Normative Documents QA API",
    description="API –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –ñ–ö–•",
    version="1.0.0",
    default_response_class=JSONResponse
)


class NumpyEncoder(json.JSONEncoder):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π encoder –¥–ª—è numpy —Ç–∏–ø–æ–≤"""
    def default(self, obj):
        if hasattr(obj, 'item'):
            return obj.item()
        elif hasattr(obj, 'tolist'):
            return obj.tolist()
        return super().default(obj)


# –ö–∞—Å—Ç–æ–º–Ω—ã–π response handler
async def custom_response(request, response):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç numpy —Ç–∏–ø—ã –≤ JSON"""
    response.media_type = "application/json"
    response.body = json.dumps(
        response.body,
        cls=NumpyEncoder,
        ensure_ascii=False
    ).encode('utf-8')
    return response

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
vectorstores: List[FAISS] = []  # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö 18 –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –±–∞–∑
document_names: List[str] = []  # –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
model: Optional[SentenceTransformer] = None


@app.on_event("startup")
async def startup_event():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ë–î –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ"""
    global vectorstores, document_names, model

    logger.info("üöÄ –ó–∞–ø—É—Å–∫ Backend API —Å–µ—Ä–≤–µ—Ä–∞...")

    if not VECTORDB_DIR.exists():
        logger.error(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {VECTORDB_DIR}")
        raise RuntimeError(f"Vector DB dir not found: {VECTORDB_DIR}")

    try:
        logger.info(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {EMBEDDING_MODEL}")
        model = SentenceTransformer(EMBEDDING_MODEL)
        embeddings = SentenceTransformerEmbeddings(model)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ 18 –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –±–∞–∑
        db_dirs = sorted([d for d in VECTORDB_DIR.iterdir()
                         if d.is_dir()
                         and not d.name.startswith('.')
                         and not d.name.startswith('unified')])  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º unified

        logger.info(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(db_dirs)} –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ë–î")

        total_vectors = 0
        for i, db_dir in enumerate(db_dirs, 1):
            try:
                logger.info(f"[{i}/{len(db_dirs)}] –ó–∞–≥—Ä—É–∑–∫–∞: {db_dir.name}")
                vs = FAISS.load_local(str(db_dir), embeddings, allow_dangerous_deserialization=True)
                vectorstores.append(vs)
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–∑–∞–º–µ–Ω–∞ _ –Ω–∞ –ø—Ä–æ–±–µ–ª –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏)
                doc_name = db_dir.name.replace('_', ' ')
                document_names.append(doc_name)
                count = vs.index.ntotal
                total_vectors += count
                logger.info(f"  ‚îú‚îÄ –í–µ–∫—Ç–æ—Ä–æ–≤: {count}")
            except Exception as e:
                logger.warning(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {db_dir.name}: {e}")

        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(vectorstores)} –ë–î, –≤—Å–µ–≥–æ {total_vectors} –≤–µ–∫—Ç–æ—Ä–æ–≤")
        logger.info("‚úÖ Backend API —Å–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        raise


@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π endpoint"""
    return {
        "service": "Normative Documents QA API",
        "status": "running",
        "version": "1.0.0"
    }


@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è"""
    return {
        "status": "healthy" if len(vectorstores) > 0 else "uninitialized",
        "model": EMBEDDING_MODEL,
        "vectordb": str(VECTORDB_DIR),
        "databases_loaded": len(vectorstores)
    }


@app.get("/stats")
async def get_stats():
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î"""
    if len(vectorstores) == 0:
        raise HTTPException(status_code=503, detail="Vector database not loaded")

    try:
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤–æ –≤—Å–µ—Ö –±–∞–∑–∞—Ö
        total_chunks = sum(vs.index.ntotal for vs in vectorstores)

        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        # –î–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–ª–∏ —Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ –æ—Ç–¥–µ–ª—å–Ω–æ
        # –ü—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± - –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        documents = set()
        # –ë–µ—Ä–µ–º –ø—Ä–∏–º–µ—Ä –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø)
        # –í —Ä–µ–∞–ª—å–Ω–æ–º —Å–ª—É—á–∞–µ –ª—É—á—à–µ —Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ë–î

        return {
            "documents_count": 18,  # –ò–∑–≤–µ—Å—Ç–Ω–æ –∏–∑ —Å–æ–∑–¥–∞–Ω–∏—è –ë–î
            "chunks_count": total_chunks,
            "model": EMBEDDING_MODEL
        }
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        raise HTTPException(status_code=500, detail=f"Stats error: {str(e)}")


@app.get("/documents")
async def get_documents():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –ë–î"""
    if len(vectorstores) == 0:
        raise HTTPException(status_code=503, detail="Vector database not loaded")

    try:
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        return {"documents": document_names}
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=f"Documents error: {str(e)}")


@app.post("/search", response_model=List[SearchResult])
async def search_documents(request: QueryRequest):
    """
    –ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º (18 –±–∞–∑)

    Args:
        request: –ó–∞–ø—Ä–æ—Å —Å —Ç–µ–∫—Å—Ç–æ–º –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    """
    if len(vectorstores) == 0:
        raise HTTPException(status_code=503, detail="Vector databases not loaded")

    try:
        import time
        total_start = time.time()

        # –®–∞–≥ 1: –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ YandexGPT –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏
        reformulate_start = time.time()
        # –ò–°–ü–†–ê–í–õ–ï–ù–û (2026-01-07): –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã –æ—Ç reformulate_query
        reformulated_query, reformulate_tokens = await reformulate_query(request.query)
        reformulate_time = time.time() - reformulate_start
        logger.info(f"‚è±Ô∏è –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ: {reformulate_time:.2f} —Å–µ–∫")

        # –®–∞–≥ 2: –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º 18 –±–∞–∑–∞–º —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å–∫–æ—Ä–∞–º–∏
        all_results = []
        per_db_k = 5  # –ë–µ—Ä–µ–º —Ç–æ–ø-5 –∏–∑ –∫–∞–∂–¥–æ–π –±–∞–∑—ã (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)

        logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–æ {len(vectorstores)} –±–∞–∑–∞–º (k={per_db_k} –∏–∑ –∫–∞–∂–¥–æ–π)")

        for i, vs in enumerate(vectorstores):
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º similarity_search_with_score —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
                docs_with_scores = vs.similarity_search_with_score(reformulated_query, k=per_db_k)
                for doc, score in docs_with_scores:
                    all_results.append((doc, float(score)))
            except KeyError as e:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∞–∑—ã —Å –æ—à–∏–±–∫–∞–º–∏ –∏–Ω–¥–µ–∫—Å–∞
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ –≤ –±–∞–∑–µ {i}: {e}")
                continue
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ {i}: {e}")
                continue

        logger.info(f"‚úÖ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(all_results)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
        search_time = time.time() - total_start
        logger.info(f"‚è±Ô∏è –ü–æ–∏—Å–∫ –ø–æ –±–∞–∑–∞–º: {search_time:.2f} —Å–µ–∫")

        # –®–∞–≥ 3: –ü–µ—Ä–≤–∏—á–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ score
        all_results.sort(key=lambda x: x[1])

        # –®–∞–≥ 3.5: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        dedup_start = time.time()
        seen_contents = {}
        unique_results = []
        duplicates_count = 0

        for doc, score in all_results:
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç–∞
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª—å—à–µ —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏ (–ø–µ—Ä–≤—ã–µ 500)
            content_key = doc.page_content[:500] if len(doc.page_content) > 500 else doc.page_content
            if content_key not in seen_contents:
                seen_contents[content_key] = True
                unique_results.append((doc, score))
            else:
                duplicates_count += 1

        dedup_time = time.time() - dedup_start
        if duplicates_count > 0:
            logger.info(f"üóëÔ∏è –£–±—Ä–∞–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count} (–∑–∞ {dedup_time:.3f} —Å–µ–∫)")
        else:
            logger.info(f"‚úÖ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ—Ç (–∑–∞ {dedup_time:.3f} —Å–µ–∫)")

        # –ë–µ—Ä–µ–º —Ç–æ–ø-20 –¥–ª—è —Ä–µ—Ä–∞–Ω–∂–∏–Ω–≥–∞
        candidates_for_rerank = unique_results[:min(len(unique_results), 20)]

        # –®–∞–≥ 4: –†–µ—Ä–∞–Ω–∂–∏–Ω–≥ —á–µ—Ä–µ–∑ YandexGPT - –û–¢–ö–õ–Æ–ß–ï–ù–û (–ø–ª–æ—Ö–∞—è —Ä–∞–±–æ—Ç–∞)
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ç–æ—á–Ω–µ–µ —á–µ–º LLM-—Ä–µ—Ä–∞–Ω–∂–∏–Ω–≥–∞
        # logger.info(f"üîÑ –†–µ—Ä–∞–Ω–∂–∏–Ω–≥ {len(candidates_for_rerank)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ YandexGPT...")
        # results_with_scores = await rerank_results_with_llm(request.query, candidates_for_rerank)

        # –®–∞–≥ 4.5: –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ (document, article) - –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –≤—Å–µ —á–∞—Å—Ç–∏ –æ–¥–Ω–æ–π —Å—Ç–∞—Ç—å–∏
        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –æ–¥–Ω–æ–π —Å—Ç–∞—Ç—å–∏, –ø–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ
        grouped_by_article = {}
        for doc, score in candidates_for_rerank:
            metadata = doc.metadata
            document = metadata.get('document', 'Unknown')
            article = metadata.get('article', '')

            # –ö–ª—é—á –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
            key = (document, article)

            if key not in grouped_by_article:
                grouped_by_article[key] = []
            grouped_by_article[key].append((doc, score))

        # –†–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –≥—Ä—É–ø–ø—ã: –±–µ—Ä–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
        results_with_scores = []
        for key, chunks in grouped_by_article.items():
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —á–∞–Ω–∫–∏ –≤–Ω—É—Ç—Ä–∏ —Å—Ç–∞—Ç—å–∏ –ø–æ score
            chunks.sort(key=lambda x: x[1])
            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ —Å—Ç–∞—Ç—å–∏
            results_with_scores.extend(chunks)

        # –õ–æ–≥–∏—Ä—É–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É
        articles_found = len(grouped_by_article)
        total_chunks = len(results_with_scores)
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {articles_found}, —á–∞–Ω–∫–æ–≤: {total_chunks}")

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º top_k (–Ω–æ —Ç–µ–ø–µ—Ä—å —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ —á–∞–Ω–∫–æ–≤ –∏–∑-–∑–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏)
        if len(results_with_scores) > request.top_k:
            results_with_scores = results_with_scores[:request.top_k]

        # –í–∞–ª–∏–¥–∞—Ü–∏—è LLM –û–¢–ö–õ–Æ–ß–ï–ù–ê - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        # –ü—Ä–∏—á–∏–Ω–∞: LLM —Å–ª–∏—à–∫–æ–º —Å—Ç—Ä–æ–≥–∏–π –∏ –±–ª–æ–∫–∏—Ä—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        formatted_results = []
        for doc, score in results_with_scores:
            try:
                metadata = doc.metadata
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã
                clean_metadata = {}
                for key, value in metadata.items():
                    if hasattr(value, 'item'):
                        clean_metadata[key] = value.item()
                    elif isinstance(value, (int, float, str, bool, list, dict, type(None))):
                        clean_metadata[key] = value
                    else:
                        clean_metadata[key] = str(value)

                # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –∏–∑ L2 —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è FAISS
                # –î–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤: cosine = 1 - (distance^2) / 2
                cosine_similarity = 1 - (float(score) ** 2) / 2
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω [0, 1]
                similarity = max(0.0, min(1.0, cosine_similarity))
                formatted_results.append(SearchResult(
                    document=str(clean_metadata.get('document', 'Unknown')),
                    article=str(clean_metadata.get('article', '')),
                    content=str(doc.page_content),
                    metadata=clean_metadata,
                    similarity=round(similarity, 4)
                ))
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
                continue

        logger.info(f"üîç –ü–æ–∏—Å–∫: '{request.query[:50]}...' -> {len(formatted_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

        # –°–æ–∑–¥–∞–µ–º –æ—Ç–≤–µ—Ç —Å –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º –∏ —Ç–æ–∫–µ–Ω–∞–º–∏
        # –ò–°–ü–†–ê–í–õ–ï–ù–û (2026-01-07): –î–æ–±–∞–≤–ª–µ–Ω—ã —Ç–æ–∫–µ–Ω—ã –≤ –æ—Ç–≤–µ—Ç
        response = SearchResponse(
            results=formatted_results,
            reformulated_query=reformulated_query,
            original_query=request.query,
            tokens_used=reformulate_tokens
        )

        # –ó–∞–º–µ—Ä—è–µ–º –æ–±—â–µ–µ –≤—Ä–µ–º—è
        total_time = time.time() - total_start
        logger.info(f"‚è±Ô∏è –û–ë–©–ï–ï –í–†–ï–ú–Ø: {total_time:.2f} —Å–µ–∫ (–ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ: {reformulate_time:.2f}s, –ø–æ–∏—Å–∫: {search_time:.2f}s, –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: {dedup_time:.3f}s)")

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º JSON
        return JSONResponse(
            content=response.model_dump()
        )

    except Exception as e:
        import traceback
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
        logger.error(f"TRACEBACK:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Search error: {str(e)}")

async def simplify_text_with_llm(text: str, max_length: int = 300) -> tuple[str, int]:
    """
    –£–ø—Ä–æ—â–∞–µ—Ç –∫–∞–Ω—Ü–µ–ª—è—Ä—Å–∫–∏–π —Ç–µ–∫—Å—Ç –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —è–∑—ã–∫

    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
        max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 300)

    Returns:
        (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π_—Ç–µ–∫—Å—Ç, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–∫–µ–Ω–æ–≤)
    """
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        logger.warning("‚ö†Ô∏è –ù–µ—Ç Yandex API –∫–ª—é—á–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç")
        return text, 0

    # –ò–°–ü–†–ê–í–õ–ï–ù–û (2026-01-07): –£–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç –¥–æ 3000 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    text_for_prompt = text[:3000] if len(text) > 3000 else text

    # –ò–°–ü–†–ê–í–õ–ï–ù–û (2026-01-07): –ü—Ä–æ–º–ø—Ç —Å –°–£–ü–ï–† –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ú –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –í–°–ï –¥–∞—Ç—ã
    prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—é —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º.

‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è –°–í–ï–†–•–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –°–û–•–†–ê–ù–ò–¢–¨ –í–°–ï –î–ê–¢–´, –ì–û–î–´, –°–†–û–ö–ò ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

–ü–†–ê–í–ò–õ–ê (–≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –¢–û–ß–ù–û):
1. –í–°–ï –¥–∞—Ç—ã –∏ —Å—Ä–æ–∫–∏ –î–û–õ–ñ–ù–´ –æ—Å—Ç–∞—Ç—å—Å—è –≤ –æ—Ç–≤–µ—Ç–µ:
   - –í—Å–µ –≥–æ–¥–∞: 2021, 2022, 2023, 2024, 2025, 2026, 2027, etc.
   - –í—Å–µ –º–µ—Å—è—Ü—ã –∏ –¥–Ω–∏
   - –í—Å–µ —á–∞—Å—ã: "24 —á–∞—Å–∞", "48 —á–∞—Å–æ–≤"
   - –í—Å–µ –ø—Ä–æ—Ü–µ–Ω—Ç—ã: "7 –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤", "14 –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤", "20 –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤"
   - –í—Å–µ —Å—É–º–º—ã: "3000 ‚ÇΩ", "10 –∫–æ–ø–µ–µ–∫"

2. –ï–°–õ–ò –í –¢–ï–ö–°–¢–ï –ï–°–¢–¨ –®–¢–†–ê–§–ù–´–ï –°–ê–ù–ö–¶–ò–ò (–¥–∞—Ç—ã 2025-2027) - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –≤–∫–ª—é—á–∏ –∏—Ö –≤ —Ä–∞–∑–¥–µ–ª **–°—Ä–æ–∫–∏**!

3. –£–∫–∞–∑—ã–≤–∞–π –ö–¢–û –∑–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç

4. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞:
   **–ì–ª–∞–≤–Ω–æ–µ:** [—Å—É—Ç—å –≤ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö]
   **–°—Ä–æ–∫–∏:** [–ø–µ—Ä–µ—á–∏—Å–ª–∏ –í–°–ï –¥–∞—Ç—ã, —Å—Ä–æ–∫–∏, –ø—Ä–æ—Ü–µ–Ω—Ç—ã]
   **–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:** [–∫—Ç–æ –∑–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç]
   **–ü–ª—é—Å:** [–≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏]

5. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞

–ü–†–ò–ú–ï–† –ü–†–ê–í–ò–õ–¨–ù–û–ì–û –û–¢–í–ï–¢–ê:
**–ì–ª–∞–≤–Ω–æ–µ:** –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É—é—â–∏–π –ø–æ—Å—Ç–∞–≤—â–∏–∫ –æ–±—è–∑–∞–Ω —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–∏–±–æ—Ä—ã —É—á–µ—Ç–∞
**–°—Ä–æ–∫–∏:**
- –Ω–µ –ø–æ–∑–¥–Ω–µ–µ 6 –º–µ—Å—è—Ü–µ–≤
- –¥–æ 31 –¥–µ–∫–∞–±—Ä—è 2023 –≥.
- –¥–æ 31 –¥–µ–∫–∞–±—Ä—è 2021 –≥.
- —à—Ç—Ä–∞—Ñ—ã: —Å 1 —è–Ω–≤–∞—Ä—è 2025 –≥. - 7%, —Å 1 —è–Ω–≤–∞—Ä—è 2026 –≥. - 14%, —Å 1 —è–Ω–≤–∞—Ä—è 2027 –≥. - 20%
**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:** –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É—é—â–∏–π –ø–æ—Å—Ç–∞–≤—â–∏–∫

–¢–µ–∫—Å—Ç –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è:
{text_for_prompt}

–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:"""

    url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
    headers = {
        "Authorization": f"Api-Key {YANDEX_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û (2026-01-07): –ü–æ–Ω–∏–∂–µ–Ω–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–æ 0.3 –¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
    body = {
        "modelUri": f"gpt://{YANDEX_FOLDER_ID}/yandexgpt-lite",
        "completionOptions": {
            "stream": False,
            "temperature": 0.3,
            "maxTokens": max_length
        },
        "messages": [
            {
                "role": "user",
                "text": prompt
            }
        ]
    }
    
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(url, headers=headers, json=body)
            response.raise_for_status()
            result = response.json()

            # –ò–°–ü–†–ê–í–õ–ï–ù–û (2026-01-07): –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞ Yandex API
            # –ë—ã–ª–æ: result["choices"][0]["message"]["text"] (—Å—Ç–∞—Ä–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ OpenAI)
            # –°—Ç–∞–ª–æ: result["result"]["alternatives"][0]["message"]["text"]
            simplified_text = result["result"]["alternatives"][0]["message"]["text"].strip()
            tokens_used = int(result["result"]["usage"].get("totalTokens", 0))

            logger.info(f"‚úÖ –¢–µ–∫—Å—Ç —É–ø—Ä–æ—â–µ–Ω: {len(text)} -> {len(simplified_text)} —Å–∏–º–≤–æ–ª–æ–≤, —Ç–æ–∫–µ–Ω–æ–≤: {tokens_used}")
            return simplified_text, tokens_used

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–ø—Ä–æ—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
        return text, 0



@app.post("/simplify", response_model=SimplifyResult)
async def simplify_text(request: SimplifyRequest):
    """
    –£–ø—Ä–æ—â–∞–µ—Ç –∫–∞–Ω—Ü–µ–ª—è—Ä—Å–∫–∏–π —Ç–µ–∫—Å—Ç –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —è–∑—ã–∫
    
    Args:
        request: –ó–∞–ø—Ä–æ—Å —Å —Ç–µ–∫—Å—Ç–æ–º –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
        
    Returns:
        –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞—Ö
    """
    try:
        simplified_text, tokens_used = await simplify_text_with_llm(
            request.text, 
            request.max_length
        )
        
        return SimplifyResult(
            original_text=request.text[:200] + "..." if len(request.text) > 200 else request.text,
            simplified_text=simplified_text,
            tokens_used=tokens_used
        )
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ endpoint simplify: {e}")
        raise HTTPException(status_code=500, detail=f"Simplification error: {str(e)}")




def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"""
    import uvicorn
    
    logger.info("=" * 80)
    logger.info("–ó–ê–ü–£–°–ö BACKEND API –°–ï–†–í–ï–†–ê")
    logger.info("=" * 80)
    logger.info(f"üìç API endpoint: http://0.0.0.0:8001")
    logger.info(f"üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://0.0.0.0:8001/docs")
    logger.info("=" * 80)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8001,
        log_level="info"
    )


if __name__ == "__main__":
    main()
